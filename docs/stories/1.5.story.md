# Story 1.5: Execute Pilot Factorial Runs

## Status
Done

## Story
**As a** research engineer orchestrating the pilot runs,
**I want** an automated cooperation runner that executes the pilot factorial design across our selected models,
**so that** we capture reproducible decision data ready for analysis within the 4-5 hour scope.

## Acceptance Criteria
1. A new CLI workflow runs all four pilot conditions with 10 runs each for every model in the 3-5 model roster, using the scenario generator with the default SeededRandom seed of 42 so every trial is reproducible. [Source: prd/pilot-study-scope-4-5-hour-implementation.md#hour-3-run-experiment][Source: prd/pilot-study-scope-4-5-hour-implementation.md#sample-size--scope][Source: prd/pilot-study-scope-4-5-hour-implementation.md#simplified-22-factorial-not-222][Source: architecture/quick-start-valid-experiment-in-4-5-hours.md#quick-start-valid-experiment-in-4-5-hours][Source: architecture/coding-standards-minimal.md#just-make-it-work]
2. Each trial persists a JSON record under `results/cooperation/` capturing the model, condition, decision, raw response, timestamp, run index, and batch identifiers aligned with the existing `GameResult` and `ExperimentBatch` contracts. [Source: architecture/source-tree.md#New File Organization][Source: architecture/data-models-simple-types.md#Minimal Types You Need][Source: docs/stories/1.3.story.md#Dev Notes][Source: architecture/quick-start-valid-experiment-in-4-5-hours.md#quick-start-valid-experiment-in-4-5-hours]
3. The runner generates a summary after completion showing total trials (≥120), decision counts per condition/model, and flags if decision extraction coverage drops below 95% so the pilot success criteria remain trackable. [Source: prd/pilot-study-scope-4-5-hour-implementation.md#sample-size--scope][Source: prd/pilot-study-scope-4-5-hour-implementation.md#success-criteria-for-pilot]
4. Operators can override the model list, run count, and seed via CLI or config parameters while defaults stay within the pilot scope, and the executed configuration (models, runs, seed, timestamp) is written to the batch manifest and console output. [Source: prd/pilot-study-scope-4-5-hour-implementation.md#sample-size--scope][Source: architecture/quick-start-valid-experiment-in-4-5-hours.md#quick-start-valid-experiment-in-4-5-hours][Source: architecture/coding-standards-minimal.md#just-make-it-work][Source: architecture/tech-stack-use-whats-already-there.md#Just Reuse Existing]

## Tasks / Subtasks
- [x] Task 1: Build the pilot batch orchestrator (AC: 1, 2)
  - [x] Implement `runPilotExperiment` that iterates the pilot conditions, configured models, and run counts while generating strategy/decision prompts with the shared SeededRandom instance. [Source: architecture/component-architecture-simplified.md#CooperationRunner][Source: architecture/quick-start-valid-experiment-in-4-5-hours.md#quick-start-valid-experiment-in-4-5-hours]
  - [x] Reuse the existing OpenRouter call, rate limiter, and decision extraction helpers so every trial returns a populated `GameResult`. [Source: docs/stories/1.1.story.md#Dev Notes][Source: architecture/component-architecture-simplified.md#CooperationRunner]
- [x] Task 2: Persist pilot outputs and manifest (AC: 2, 4)
  - [x] Save each trial to `results/cooperation/` using deterministic filenames that encode model, condition label, run index, and timestamp while writing the serialized `GameResult`. [Source: architecture/source-tree.md#New File Organization][Source: architecture/data-models-simple-types.md#Minimal Types You Need]
  - [x] Aggregate per-model batches into an `ExperimentBatch` summary that stores the seed, model roster, total trial count, and file paths, and write it alongside the trial outputs. [Source: docs/stories/1.3.story.md#Dev Notes][Source: prd/pilot-study-scope-4-5-hour-implementation.md#sample-size--scope]
- [x] Task 3: Expose a `run-pilot` CLI command (AC: 1, 4)
  - [x] Extend the `import.meta.main` switch to handle a `run-pilot` command with optional `--models`, `--runs`, and `--seed` arguments, enforcing the 3-5 model constraint. [Source: prd/pilot-study-scope-4-5-hour-implementation.md#sample-size--scope][Source: architecture/quick-start-valid-experiment-in-4-5-hours.md#quick-start-valid-experiment-in-4-5-hours]
  - [x] Log the resolved configuration (models, run count, seed) before execution and serialize it into the batch manifest for reproducibility. [Source: architecture/coding-standards-minimal.md#just-make-it-work][Source: architecture/data-models-simple-types.md#Minimal Types You Need]
- [x] Task 4: Produce decision coverage summaries (AC: 3)
  - [x] After all runs, compute per-condition and per-model decision totals plus unmatched counts, asserting ≥10 runs per condition and ≥95% extraction coverage with warning output when thresholds are missed. [Source: prd/pilot-study-scope-4-5-hour-implementation.md#hour-3-run-experiment][Source: prd/pilot-study-scope-4-5-hour-implementation.md#success-criteria-for-pilot]
  - [x] Persist the summary statistics (counts, coverage, warnings) next to the batch manifest for analysis handoff. [Source: architecture/source-tree.md#New File Organization][Source: architecture/data-models-simple-types.md#Minimal Types You Need]
- [x] Task 5: Document operator verification steps (AC: 3)
  - [x] Update the README pilot section with instructions for running `run-pilot`, verifying JSON outputs, and spot-checking decisions per the manual testing guidance. [Source: architecture/testing-skip-for-now.md#Manual Testing Only][Source: prd/pilot-study-scope-4-5-hour-implementation.md#success-criteria-for-pilot]

## Dev Notes

### Previous Story Insights
- Scenario previews already pull every symmetry/coupling combination with SeededRandom defaulting to 42, so the batch runner should reuse that deterministic seed to keep prompt content aligned. [Source: docs/stories/1.4.story.md#Dev Notes]
- Cooperation types and result structures were standardized in Story 1.3; consuming those interfaces prevents divergence when persisting pilot outcomes. [Source: docs/stories/1.3.story.md#Dev Notes]
- The OpenRouter integration, environment validation, and rate limiter are in place from Story 1.1—extend them rather than creating new API plumbing. [Source: docs/stories/1.1.story.md#Dev Notes]

### Data Models
- Persisted trials must include `model`, `condition`, `decision`, `response`, and `timestamp` fields following the minimal data model, while the pilot condition remains limited to symmetry and coupling. [Source: architecture/data-models-simple-types.md#Minimal Types You Need][Source: prd/pilot-study-scope-4-5-hour-implementation.md#simplified-22-factorial-not-222]
- Batch metadata should leverage the `ExperimentBatch` structure introduced in Story 1.3 to capture IDs, seed, and execution window. [Source: docs/stories/1.3.story.md#Dev Notes]

### API Specifications
No specific guidance found in architecture docs.

### Component Specifications
- CooperationRunner is responsible for looping conditions, calling OpenRouter, extracting decisions, and saving JSON outputs; the pilot runner should build on that flow. [Source: architecture/component-architecture-simplified.md#CooperationRunner]
- ScenarioGenerator should provide both strategy and decision prompts for every trial so the runner can deliver the correct phase content to the agents. [Source: architecture/component-architecture-simplified.md#ScenarioGenerator]

### File Locations
- Keep the runner and supporting utilities in `src/cooperation/` and persist outputs under `results/cooperation/` per the documented source tree. [Source: architecture/source-tree.md#New File Organization]
- Scenario artifacts remain in `scenarios/cvd/`, so any additional templates or previews generated during runs should align with that directory. [Source: architecture/source-tree.md#New File Organization]

### Testing Requirements
- Follow the manual testing guidance: execute a single-model dry run first, confirm decision extraction, and inspect JSON outputs before scaling to the full roster. [Source: architecture/testing-skip-for-now.md#Manual Testing Only]

### Technical Constraints
- Pilot scope limits runs to 3-5 models, 10 runs per condition, 120-200 total trials, with a ~$1-2 budget and ~15-20 minute runtime—keep defaults within these caps. [Source: prd/pilot-study-scope-4-5-hour-implementation.md#sample-size--scope]
- Maintain the fixed seed default (42) and avoid introducing new dependencies so runs stay reproducible and within the rapid implementation window. [Source: architecture/coding-standards-minimal.md#just-make-it-work][Source: architecture/tech-stack-use-whats-already-there.md#Dont Add Anything New]

### Project Structure Notes
- Store batch manifests and summaries alongside trial JSON files to keep cooperation outputs co-located for the forthcoming analysis story. [Source: architecture/source-tree.md#New File Organization][Source: prd/pilot-study-scope-4-5-hour-implementation.md#hour-4-basic-analysis]

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-09-22 | 0.1 | Initial draft | Bob (SM) |
| 2025-09-22 | 0.2 | Implemented pilot runner CLI, persistence, and summaries | James (dev) |

## Dev Agent Record

### Agent Model Used

- GPT-5 (Codex)

### Debug Log References

- .ai/debug-log.md (2025-09-22 dry-run pilot validations)

### Completion Notes List

- Added `runPilotExperiment` orchestrator with deterministic SeededRandom prompts, per-model batches, and manifest/summary persistence.
- Extended CLI with `run-pilot` command supporting model/run/seed overrides and output logging.
- Documented operator flow in README, defaulted pilot roster to Gemini Flash variants to minimize spend, and captured dry-run coverage via Bun test to keep regression green.

### File List

- src/cooperation/index.ts
- src/cooperation/types.ts
- src/cooperation/__tests__/pilot-runner.test.ts
- README.md
- .ai/debug-log.md

## QA Results
### 2025-09-22 — Quinn (Test Architect & Quality Advisor)
- **Gate Decision:** PASS — pilot runner executes the seeded factorial workflow, persists manifest/summary artifacts, and surfaces coverage warnings without blocking issues.
- **Acceptance Evidence:**
  - *AC1 (run all pilot conditions with seeded reproducibility):* `runPilotExperiment` defaults to 10 runs, enforces a 3-5 unique model roster, seeds `createSeededRandom` to 42, and iterates every entry in `PILOT_CONDITIONS` while building prompts and invoking OpenRouter per run (`src/cooperation/index.ts:480`, `src/cooperation/index.ts:524`, `src/cooperation/index.ts:546`, `src/cooperation/index.ts:557`).
  - *AC2 (persist per-trial JSON with required fields):* Each `GameResult` captures model, condition, decision, response, timestamp, run index, and batch id before `persistPilotTrial` writes deterministic filenames under `results/cooperation/` (`src/cooperation/types.ts:31`, `src/cooperation/index.ts:567`, `src/cooperation/index.ts:299`).
  - *AC3 (summaries and coverage flags):* `createDecisionSummary` aggregates per-model/condition counts, computes coverage, and queues warnings when totals or coverage drop below thresholds before the manifest/summary JSON files are written next to the trials (`src/cooperation/index.ts:316`, `src/cooperation/index.ts:392`, `src/cooperation/index.ts:623`, `src/cooperation/index.ts:642`).
  - *AC4 (operator overrides and run logging):* CLI parsing surfaces `--models`, `--runs`, `--seed`, and `--output` overrides, while README instructions walk operators through default and custom runs plus output locations (`src/cooperation/index.ts:713`, `README.md:18`).
- **Test Notes:** `bun test src/cooperation/__tests__/pilot-runner.test.ts` verifies the dry-run pathway produces manifest, summary, and per-model trial files with full coverage and zero warnings (`src/cooperation/__tests__/pilot-runner.test.ts:8`).
- **Risks & Follow-ups:**
  - Shared RNG state advances continuously across the model roster; if analysis expects identical scenario text per condition across models, consider seeding per-model to keep flavor cues aligned while retaining reproducibility (`src/cooperation/index.ts:524`).
